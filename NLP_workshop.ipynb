{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8oaT8xJWIR97jQeSE/K/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KiroSafwat/NLP_workshop/blob/main/NLP_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GjQYQAF-rtk",
        "outputId": "e022e42b-04cc-40ed-c999-6ed0eba17bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('twitter_training.csv', header=None, encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "CLRgcw73_Ebr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0MnXzJxA12C",
        "outputId": "80bcb84c-cc5c-410c-b86b-4363e89b3ff3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1v-muDrBYTp",
        "outputId": "929c6895-9f60-4f7f-c385-fb573093f607"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index([0, 1, 2, 3], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', str(text), flags=re.MULTILINE)\n",
        "\n",
        "df['clean_tweet'] = df[3].apply(remove_urls)\n",
        "\n",
        "print(df[['clean_tweet']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv4CG9g6A3uL",
        "outputId": "dcb0ac86-f8c9-4873-8685-58824637e68a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         clean_tweet\n",
            "0  im getting on borderlands and i will murder yo...\n",
            "1  I am coming to the borders and I will kill you...\n",
            "2  im getting on borderlands and i will kill you ...\n",
            "3  im coming on borderlands and i will murder you...\n",
            "4  im getting on borderlands 2 and i will murder ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_mentions(text):\n",
        "    return re.sub(r'@\\w+', '', text)\n",
        "\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(remove_mentions)\n",
        "print(df[['clean_tweet']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg3niOVDCBTJ",
        "outputId": "1bacbd25-88c9-4a9b-fef3-f44b4e058254"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         clean_tweet\n",
            "0  im getting on borderlands and i will murder yo...\n",
            "1  I am coming to the borders and I will kill you...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_hashtags(text):\n",
        "    return re.sub(r'#', '', text)\n",
        "\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(clean_hashtags)\n",
        "print(df[['clean_tweet']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM1v0bDyCbEx",
        "outputId": "a406cfa2-3488-419a-a1f0-501ede6a6688"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         clean_tweet\n",
            "0  im getting on borderlands and i will murder yo...\n",
            "1  I am coming to the borders and I will kill you...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_tweet'] = df['clean_tweet'].astype(str).str.lower()\n",
        "print(df[['clean_tweet']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXHSnm3pCgna",
        "outputId": "a5d54f94-aed5-4b70-8f01-cfb027ed04d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         clean_tweet\n",
            "0  im getting on borderlands and i will murder yo...\n",
            "1  i am coming to the borders and i will kill you...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(remove_punctuation)\n",
        "print(df[['clean_tweet']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0V30_kKCloz",
        "outputId": "41a61d3f-8534-4ad4-9b19-9d9a72d918e6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         clean_tweet\n",
            "0  im getting on borderlands and i will murder yo...\n",
            "1  i am coming to the borders and i will kill you...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(remove_numbers)\n",
        "print(df[['clean_tweet']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAi3qDPWCqo_",
        "outputId": "386f6abd-2288-446a-cd60-832af20680b5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         clean_tweet\n",
            "0  im getting on borderlands and i will murder yo...\n",
            "1  i am coming to the borders and i will kill you...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyoRRHRGDrLs",
        "outputId": "6855a0c5-1f93-4cb4-a3db-56eda1c41dea"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df['tokens'] = df['clean_tweet'].apply(lambda x: x.split())\n",
        "\n",
        "print(\"--- 2. Tokenization Complete ---\")\n",
        "print(df[['tokens']].head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHaip5LQCuMk",
        "outputId": "aa6b7460-a30d-47ef-a82e-cd77de95010f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2. Tokenization Complete ---\n",
            "                                              tokens\n",
            "0  [im, getting, on, borderlands, and, i, will, m...\n",
            "1  [i, am, coming, to, the, borders, and, i, will...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "df['final_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "Y = df[2]\n",
        "\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 3)\n",
        ")\n",
        "X = tfidf_vectorizer.fit_transform(df['final_text']).toarray()\n",
        "\n",
        "print(f\"--- 4. Vectorization (TF-IDF) Complete ---\")\n",
        "print(f\"Feature matrix shape (X): {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX7gV--hEZUa",
        "outputId": "20127433-740c-41b9-fa60-33a7d28b2f3b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 4. Vectorization (TF-IDF) Complete ---\n",
            "Feature matrix shape (X): (74682, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42,)\n",
        "\n",
        "print(\"--- 5. Train-Test Split Complete ---\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLe-SlUyE3IZ",
        "outputId": "c63290d9-a96e-4b24-92fd-64eaaaa75328"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 5. Train-Test Split Complete ---\n",
            "X_train shape: (59745, 5000)\n",
            "X_test shape: (14937, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Logistic Regression model and evaluation metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# --- 6. MODEL TRAINING ---\n",
        "\n",
        "# 1. Initialize the model\n",
        "# We set max_iter to a higher value for convergence on larger datasets\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# 2. Train the model using the training data\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "print(\"--- Model Training Complete ---\")\n",
        "\n",
        "# 3. Make predictions on the test set\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# 4. Evaluate the model\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "report = classification_report(Y_test, Y_pred)\n",
        "\n",
        "print(f\"\\nAccuracy Score: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report (Detailed Results):\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpnxQBpyFpPY",
        "outputId": "9de43404-3392-4cb1-a7d4-902b2effb99c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model Training Complete ---\n",
            "\n",
            "Accuracy Score: 0.6649\n",
            "\n",
            "Classification Report (Detailed Results):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.64      0.49      0.55      2592\n",
            "    Negative       0.71      0.76      0.73      4519\n",
            "     Neutral       0.60      0.61      0.61      3596\n",
            "    Positive       0.68      0.72      0.70      4230\n",
            "\n",
            "    accuracy                           0.66     14937\n",
            "   macro avg       0.66      0.64      0.65     14937\n",
            "weighted avg       0.66      0.66      0.66     14937\n",
            "\n"
          ]
        }
      ]
    }
  ]
}